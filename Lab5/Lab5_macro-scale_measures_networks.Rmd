---
title: "STAT332 Statistical Analysis of Networks Sec 01 - Lab 5 - Prof. Joe Reid"
author: "Andrew Sparkes"
date: "`r Sys.Date()`"
due: "20-02-2026"
output:
  html_document:
    self_contained: true
    df_print: paged
    code_folding: show
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)

library(igraph) 
library(igraphdata)

library(data.table)
library(gt)

library(patchwork)
library(ggraph)
```


```{r user_configurable_settings}
gml_file <- "Caviar.graphml"

SKIP_AHEAD <- FALSE # to skip outputting the introductory sections, TRUE for omit, FALSE for display all
```

```{r extra_functions}
print_igraph_attr <- function(graph) {
  print("--- Graph Attributes ------")
  print(graph_attr(graph))

  print("--- Vertex Attributes ------")
  print(vertex_attr(graph))

  print("--- Edge Attributes ------")
  print(edge_attr(graph))
}
```

`r if(SKIP_AHEAD) {"Commenting out middle part to skip to the relevant bits!\\n\\n... snip ...\\n\\begin{comment}"}`

`r if(SKIP_AHEAD) {"\\end{comment}"}`


## 1.) Setup

Welcome to Lab 5. This week we are going to be focused on macro-scale measures on networks.

For our dataset this week, we're going to use the classic `karate` network.

## 2.) Lab Walkthrough

### 2.a) Getting started.

```{r load_in_the_dataset}
#library(igraph) # moved all imports to top of file
#library(igraphdata) # moved all imports to top of file
data(karate)
g <- karate
```

As always, let's make sure we print out our vertex and edge attributes:

```{r summarize_the_dataset}
summary(g)
```

So $34$ nodes, undirected, weighted, and $78$ edges.

EDITOR'S NOTE: Because this is a relatively small network with a measly $34$ nodes and $78$ edges, let's do a dump of the attributes, just for curiosities sake:

```{r dump_the_graph_attributes}
print_igraph_attr(g)
```

And again, lets use a summary for finding out other properties.

```{r make_table_of_properties, message = FALSE, warning=FALSE}
#library(data.table) # moved all imports to top of file
#library(gt) # moved all imports to top of file

ID = c("Order", "Size", "Connected", "Directed", "Acyclic", "Weighted", "Simple", "Has Loops", "Is Multigraph", "Bipartite", "Tree", "Forest")
  
Value = c(gorder(g), ecount(g), is_connected(g), is_directed(g), is_acyclic(g), is_weighted(g), is_simple(g), any_loop(g), any_multiple(g), is_bipartite(g), is_tree(g), is_forest(g))
  
table <- data.table(ID, Value)
table %>% gt() %>% fmt_tf(columns = Value, tf_style = "yes-no")
```

It's connected, so we don't need to worry about the largest component. If we did, you could use: `g2 \<- largest_component(g)` to extract it to `g2`.

This still isn't quite enough information to work with. We have a weighted graph, so we need to know if the edge weights are distances or strengths.

```{r help_i_need_somebody_help}
?karate
```

So, it looks like these are STRENGTH based associations. Distances should then be calculated and added as an edge property. Let's do that (normalizing based on Osphel's suggestion.)

```{r convert_from_strengths_to_distances}
E(g)$distance_weight <- 1 / (E(g)$weight / mean(E(g)$weight))
```

I think that's enough for the setup, so let's move on to clustering.

# 3.) Community Detection

Remember how we discussed a LOT of community detection methods. Some were density based, some were structure/truss based, and some are clique based? Very few of the ones we discussed are implemented in igraph, but it's enough for our purposes. Let's start with the general density based ones.

In R we have the following functions readily available:

-   `cluster_leiden()`

-   `cluster_louvain()`

-   `cluster_edge_betweenness()` \<- this is the Girvan-Newman algorithm

-   `cluster_fast_greedy()` \<- maximizes modularity directly using the Clauset Newman and Moore method for very large networks. It doesn't actually find the max, but goes straight for it.

-   `cluster_leading_eigen()`

-   `cluster_spinglass()` \<- can work with networks that have negative weights on edges.

-   `cluster_walktrap()`

-   `cluster_infomap()`

-   `cluster_fluid_communities()` \<- cluster based on interacting fluids

-   `cluster_label_prop()` \<- neighborhood voting membership

-   `cluster_optimal()` \<- not recommended. It maximizes modularity using an NP-complete problem method based on integer programming. May take a _**LONG**_ time.

-   `coreness()` \<- k-core decomposition

-   `cliques()` \<- find fully connected subgraphs.

As an interesting note, communities objects in `igraph` are a special type of object that have an entire set of methods at our disposal for.

<https://r.igraph.org/reference/communities.html>

Let's go ahead.

![Reminder of community detection methods based on density](Community Based Detection.png)

## Cluster Leiden

<https://r.igraph.org/reference/cluster_leiden.html>

```         
cluster_leiden(graph,   
  objective_function = c("CPM", "modularity"),   
  ...,   
  weights = NULL,   
  resolution = 1,   
  resolution_parameter = deprecated(),   
  beta = 0.01,   
  initial_membership = NULL,   
  n_iterations = 2,   
  vertex_weights = NULL )
```

Since we covered modularity in class, let's go with that. For our weights, we want to use the right weights, but reading the documentation, "A larger edge weight means a stronger connection for this function." This means that the default weights are correct. `resolution` is the parameter for granularity (higher is more granular, lower leads to broader communities). `beta` is a randomness parameter for the refinement.

```{r leiden_hosen_dat_graphen}
leiden_g <- cluster_leiden(g,
                           objective_function = "modularity",
                           weights = E(g)$weight,
                           resolution = 1,
                           n_iterations = 6,
                           vertex_weights = NULL)
```

Okay, we ran it. Now what? Well, `leiden_g` is a graph object. Try plotting it!

```{r plot_the_leiden_graph}
plot(leiden_g, g)
```

Hey!!! We get something cool!

Let's explore the community results a little bit more.

```{r calculate_membership_of_leiden_graph}
membership(leiden_g)
```

Membership gives us the list of membership values for every node in the network.

For a small network, it's easy to see the total number of communities. But...

```{r calculate_length_of_leiden_graph}
length(leiden_g)
```

```{r calculate_community_sizes_of_leiden_graph}
sizes(leiden_g)
```

If we wanted to know the relative sizes of the communities we can use `sizes()`. And, just in case you don't remember what algorithm you used to get that specific type of membership...

```{r display_algorithm_used}
algorithm(leiden_g)
```

By the way, you might expect that the communities were stored into the original graph object, but...

```{r resummarize_g_and_they_are_all_gone_omg}
summary(g)
```

Merges won't do anything for us right now because Leiden isn't a hierarchical method so we'll come back to that along with dendograms. If you want to test that, you can use `is_hierarchical(leiden_g)`.

That's about it for the general overview, and we aren't going to do this for every method, but we can move along now.

## Cluster Louvain

-   `cluster_louvain()` <https://r.igraph.org/reference/cluster_louvain.html>

Once again, larger edge weight means a stronger connection, so we're good with the default weights, but this is a **MUCH** simpler function on our part.

```         
cluster_louvain(graph, weights = NULL, resolution = 1)
```

```{r create_louvain_clustering}
louvain_g  <- cluster_louvain(g, weights = E(g)$weight, resolution = 1)
```

```{r plot_the_louvain_clustering}
plot(louvain_g, g)
```

Woah! Well that looks different. By the way, the node colors are from the vertex "faction" value so, that might be something interesting to consider.

## Cluster Edge Betweenness

<https://r.igraph.org/reference/cluster_edge_betweenness.html>

```         
cluster_edge_betweenness(graph,   
  weights = NULL,   
  directed = TRUE,   
  edge.betweenness = TRUE,   
  merges = TRUE,   
  bridges = TRUE,   
  modularity = TRUE,   
  membership = TRUE )
```

Going back to the documentation, this time "Edges are interpreted as distances, not as connection strengths." So this time, we need to use our normalized and inverted weights.

```{r calculate_cluster_edge_betweenness}
gn_g <- cluster_edge_betweenness(g,
                                 weights = E(g)$distance_weight)
```

Just a quick note on this one; `merges = TRUE`. We can print out the merges (I'll just print the first few). This is the order the tree was built in.

```{r check_first_merges}
head(merges(gn_g))
```

```{r plot_the_clusters_by_edge_betweenness}
plot(gn_g, g)
```

But this one identifies two (overlapping) communities based on these results? Actually, if you look carefully at the membership values, they aren't overlapping. Remember that there are $34$ vertices?

```{r doublecheck_community_sizes_in_clustering}
sizes(gn_g)
```

The geometry of the plot just makes it look that way. But, we can get a little more information out of this method.

```{r check_if_clustering_is_hierarchical}
is_hierarchical(gn_g)
```

```{r convert_clustering_to_dendogram}
as.dendrogram(gn_g, use.modularity = TRUE)
```

```{r plot_the_dendrogram}
plot_dendrogram(gn_g)
```

## Cluster Leading Eigenvector

<https://r.igraph.org/reference/cluster_leading_eigen.html>

```         
cluster_leading_eigen(graph,  
  steps = -1,   
  weights = NULL,   
  start = NULL,   
  options = arpack_defaults(),   
  callback = NULL,   
  extra = NULL,   
  env = parent.frame() )
```

Once again, we have to check the weights. This time, we're back to large value being strength of ties so we can use the built in strengths. We don't have to change anything else, so...

```{r calculate_cluster_leading_eigenvector}
eigen_g <- cluster_leading_eigen(g, weights = E(g)$weight)
```

```{r plot_with_cluster_leading_eigenvector}
plot(eigen_g, g)
```

I think you've got the idea by now. We haven't explored `walktrap` or `infomap` for these (both random walk methods where the edge weight has a "stronger is higher" needed.) But, I think it's time that we get to the other two that are available.

## K Core Decomposition

<https://r.igraph.org/reference/coreness.html>

![Figure showing K-core decomposition algorithm](K-core.png)

K-core looks for cores of the network. There isn't too much to the code.

```         
coreness(graph, mode = c("all", "out", "in"))
```

```{r calculate_the_k_core}
k_core_g <- coreness(g, mode = "all")
```

`k_core_g` is not a graph object. It records the k-index when the nodes are removed from the graph.

```{r setup_and_plot_k_core_subgraph}
#library(patchwork) # all imports moved to top of file
#library(ggraph) # all imports moved to top of file

V(g)$core <- k_core_g # storing the already calculated k-core in the vertices' core attr

set.seed(1) # static seed for repeatability FOR NOW
L <- layout_with_fr(g) # Fruchterman-Reingold layout

ks <- sort(unique(V(g)$core)) # sorted vector of distinct k-core values
ks <- ks[ks > 0]  # drop 0-core isolates (not necessary here, but if you want to use this code it might help)
# the above line uses bool indexing and I get that, and I /think/ I understand a 0-core to basically be the same exact graph (all vertices would have 0 or more, right???), TODO am I missing something? Assuming Joe dropped for a good reason

# okay, breaking this down, looks like we are mapping over our distinct k-core values (in order, per sort call above), expecting a list return type and performing an anonymous function that is long enough to where it probably should be a _named_ function. Let's poke at it and comment on what it's doing...
plots <- lapply(ks, function(k){
  keep <- V(g)$core >= k # for any k passed in, keep holds the bool vector of vertex indices with >=k core
  sg <- induced_subgraph(g, vids = V(g)[keep]) # making a new subgraph consisting of just the vertices that have >= current k-core (and any connecting edges between them)

  # subset the full-graph layout to this subgraph's vertices (keeps positions stable)
  idx <- as.integer(V(g)[keep])        # vertex ids in original graph
  Lk  <- L[idx, , drop = FALSE] # subsetting the fr layout with the "keep" vertex ids/indices, the entire "row", and passing drop=FALSE ensures we get a df back out

  # passing along our subgraph to ggraph, manual layout with our Lk values from above loc
  ggraph(sg, layout = "manual", x = Lk[,1], y = Lk[,2]) +
    
    # now, adding relatively transparent mid gray edges connecting the vertices
    geom_edge_link(alpha = 0.25, colour = "grey60") +
    
    # adding the vertices, colored based on their k-core value, static size of 2.5
    geom_node_point(aes(color = core), size = 2.5) +
    
    # adding text labels, pulled from name attr, static size of 3, with a vertical adjustment
    geom_node_text(aes(label = name),
                 size = 3,
                 vjust = 1.5) +
    
    # setting the color scale, option D is viridis (the green/blue gradient one), excellent choice, the end param sets the end of the color hue range from [0,1] to [0, 0.95]
    # calling scale_color_viridis_c(), noting the _c ending, confused me for a while now, and it just dawned on me after reading the ggplot2 docs that that _c doesn't mean color option c, it stands for continuous, as opposed to d for discrete, or apparently b for binned color maps... Today I learned a thing...
    scale_color_viridis_c(option = "C", end = 0.95) +
    
    # add a plot title, indicating the current k value, as well as the number of vertices and edges in the subgraph
    ggtitle(paste0(k, "-core (core ≥ ", k, "), n=", vcount(sg), ", m=", ecount(sg))) +
    
    # blank theme with just default font size set
    theme_void(base_size = 11) +
    
    # nullify the legend, and set the plot title to be smaller font face and bolded
    theme(legend.position = "none",
          plot.title = element_text(size = 10, face = "bold"))
  
  # no explicit return, so that ggraph is the return obj
})

# from what I am guessing, this will distribute the plots among a 2-col grid layout, for as many plots exist in ... well, plots. I'm relating this to patchwork or kinda like faceting behavior... edit 27 minutes later, when I notice what package wrap_plots is from, and didn't notice when copying its library call to top of file.... Argh!
wrap_plots(plots, ncol = 2)

```

```{r do_the_same_for_k_shell_plots}

# alright, looks like we're applying a similar function as above over our kept k-cores, ks, expecting a list back and assigning to shell_plots
shell_plots <- lapply(ks, function(k){
  # identical as above, calculating k-cores and making a subgraph of them and their edges
  keep <- V(g)$core == k
  sg <- induced_subgraph(g, vids = V(g)[keep])

  # again, getting the indices and doing some magic before indexing the layout and storing the coords
  idx <- as.integer(V(g)[keep])
  Lk  <- L[idx, , drop = FALSE]

  ggraph(sg, layout = "manual", x = Lk[,1], y = Lk[,2]) + # same manual layout
    
    # this line differs. static vertex size and color... Hmmmm...
    geom_node_point(size = 2.5, color = "#2C7FB8") +
    
    # identical
    geom_node_text(aes(label = name),
                 size = 3,
                 vjust = 1.5) +
    
    # the key difference is a missing call to any ggraph function that adds edges/links, so only the vertices will display. 
    
    # title the plot with the k-shell value, k-core value, and the vertex count
    ggtitle(paste0(k, "-shell (core == ", k, "), n=", vcount(sg))) +
    
    # blank theme with base font size 11
    theme_void(base_size = 11)
})

# wraps the plots, however many there may be, in a 2-col grid style layout
wrap_plots(shell_plots, ncol = 2)

```

## Cliques

Finally, let's find the cliques in the graph. <https://r.igraph.org/reference/cliques.html>

```         
cliques(graph, min = NULL, max = NULL, ..., callback = NULL)
```

```{r count_the_cliques}
clique_num(g)
```

The maximum clique size within this graph is $5$ individuals.

```{r}
cliques(g, min = 5) # finds cliques that are 5 members or larger? that's what I'm interpreting from ?cliques TODO google me!
```

These are the actors which form the full graphs in the network. Four of the members are the same in these cliques and only one actor is different. If you inspect the factions of the vertex labels (after the split in the karate club), you'll notice that this entire clique stuck with Mr Hi. This is unsurprising and could have been easily predicted. An interesting question to explore would be if the size $4$ cliques splintered between factions or if they remained cohesive through the split.

---



## 4.) Your turn:

### Dataset Description:

_Project Caviar_ was a unique investigation that targeted a network of hashish and cocaine importers operating out of Montreal. The network was targeted between **1994** and **1996** by a tandem investigation uniting the Montreal Police, the Royal Canadian Mounted Police, and other national and regional law-enforcement agencies from various countries (i.e. England, Spain, Italy, Brazil, Paraguay, and Colombia). The case is unique because it involved a specific investigative approach that will be referred to as a “seize and wait” strategy. Unlike most law-enforcement strategies, the mandate set forward in the _Project Caviar_ case was to seize identified drug consignments, but not to arrest any of the identified participants. This took place over a **2**-year period. Thus, although **11** importation consignments were seized at different moments throughout this period, arrests only took place at the end of the investigation. What this case offers is a rare opportunity to study the evolution of a criminal network phenomenon as it was being disrupted by law-enforcement agents. The inherent investigative strategy permits an assessment of change in the network structure and an inside look into how network participants react and adapt to the growing constraints set upon them. 

The principal data source was comprised of information submitted as evidence during the trials of **22** participants in the Caviar network. It included **4,279** paragraphs of information (over **1,000** pages) revealing electronically intercepted telephone conversations between network participants. These transcripts were used to create the overall matrix of the drug-trafficking operation’s communication system throughout the course of the investigation. Individuals falling in the surveillance net were not all participants in the trafficking operation. An initial extraction of all names appearing in the surveillance data led to the identification of **318** individuals. From this pool, **208** individuals were not implicated in the trafficking operations. Most were simply named during the many transcripts of conversations, but never detected. Others who were detected had no clear participatory role within the network (e.g., family members or legitimate entrepreneurs). The final network was thus composed of **110** participants. 

### Network
# TODO FORMAT THIS BETTER
**11**x **1**-mode matrices person by person, representing the **11** phases of the investigation. **_Ties_** are _directed_ **and** _valued_. Number of nodes:
1) **15**x**15**
2) **24**x**24**
3) **33**x**33**
4) **33**x**33**
5) **32**x**32**
6) **27**x**27**
7) **34**x**34**
8) **42**x**42**
9) **34**x**34**
10) **42**x**42**
11) **41**x**41**

**1**-mode matrix **110** x **110** person by person of the complete network. **_Ties_** are communication exchanges between criminals. **_Values_** represent level of communication activity. Data comes from police wiretapping.

Why yes, yes I did copy/paste that from Lab 4 and didn't want to reformat that blob of text. You worked with this same `graphml` object last week. I'd like you to use a variety of the above algorithms to try to discover meso-scale structural patterns within this dataset.

```{r load_in_the_gml_file}
g <- igraph::read_graph(gml_file, format = "graphml")
g
print_igraph_attr(g)
```

```{r load_in_dataset}
# project caviar engage

```

Who are the core members?

```{r find_core_members}
# TODO core members
```

Are there membership cliques?

```{r membership_cliques}
# TODO membership cliques
```

What communities can you find using density methods and how could this be helpful at finding the key operations?

```{r communities}
# TODO communities
```

Next, please provide a few paragraphs regarding these measures and what they imply about the structure of this drug smuggling network.

**Answer:**
# TODO ME

## 5.) Results

What you need to do next is to "knit" your document into an html using the "Knit" button near the top of the screen. This will give you an HTML that you can turn in.






















EXTRA REFERENCE

```{r}
# TODO calculate a tribble full of the various measurement values
global_measures_data <- tribble(
  ~Measure, ~Meaning, ~Category, ~Disconnected, ~Multigraphs_Loops, ~Strength_Weights, ~Distance_Weights,

  # --------------------- STRUCTURAL ---------------------
  "Diameter", "Longest shortest path", "Structural", "Largest Component", "Collapse; remove loops", "1/weight", "✓",

  "Conductance", "Global bottleneck ratio", "Structural", "Largest Component", "Collapse", "✓", "✓",

  "Adhesion (Edge Connectivity)", "Minimum edges to disconnect graph", "Structural", "✓", "Collapse or merge multiplicity", "✓", "✓",

  "Vertex Connectivity", "Minimum vertices to disconnect", "Structural", "✓", "Collapse", "Irrelevant", "Irrelevant",

  "Algebraic Connectivity (λ₂)", "Spectral connectivity (Fiedler value)", "Structural", "Largest Component", "Collapse; remove loops", "✓", "Do NOT use",

  # --------------------- INTERCONNECTEDNESS ---------------------
  "Edge Density", "Edges ÷ possible edges", "Interconnectedness", "✓", "Collapse", "Irrelevant", "Irrelevant",

  "Network Cohesion (Reachability Ratio)", "Fraction of reachable ordered pairs", "Interconnectedness", "✓", "Collapse", "Irrelevant", "Irrelevant",

  "Global Clustering Coefficient", "Triangle closure ratio", "Interconnectedness", "✓", "Collapse", "✓ (Barrat local → mean)", "Irrelevant",

  "Assortativity", "Mixing by attribute", "Interconnectedness", "✓", "Collapse", "✓ (strength assort.)", "✓ (degree assort.)",

  # --------------------- CENTRALIZATION ---------------------
  "Degree Centralization", "Inequality of degree distribution", "Centralization", "✓", "Collapse", "Consider Strength Centralization", "✓",

  "Strength Centralization", "Inequality of weighted degree", "Centralization", "✓", "Collapse", "✓", "Irrelevant",

  "Closeness Centralization", "Inequality in closeness", "Centralization", "Largest Component", "Collapse", "1/weight", "✓",

  "Betweenness Centralization", "Inequality in shortest path mediation", "Centralization", "Largest Component", "Collapse", "1/weight", "✓",

  "Eigenvector Centralization", "Inequality in spectral influence", "Centralization", "✓", "Collapse", "✓", "Do NOT use",

  # --------------------- EFFICIENCY ---------------------
  "Global Efficiency", "Global ease of communication", "Efficiency", "✓", "Collapse", "1/weight", "✓",

  "Average Local Efficiency", "Neighborhood-level efficiency", "Efficiency", "✓", "Collapse", "1/weight", "✓",

  "Average Shortest Path Length", "Mean geodesic distance", "Efficiency", "Largest Component", "Collapse", "1/weight", "✓"
)
```

```{r display_measures}
global_measures_table <- tribble(
  ~Measure, ~Meaning, ~Category, ~Disconnected, ~Multigraphs_Loops, ~Strength_Weights, ~Distance_Weights,

  # --------------------- STRUCTURAL ---------------------
  "Diameter", "Longest shortest path", "Structural", "Largest Component", "Collapse; remove loops", "1/weight", "✓",

  "Conductance", "Global bottleneck ratio", "Structural", "Largest Component", "Collapse", "✓", "✓",

  "Adhesion (Edge Connectivity)", "Minimum edges to disconnect graph", "Structural", "✓", "Collapse or merge multiplicity", "✓", "✓",

  "Vertex Connectivity", "Minimum vertices to disconnect", "Structural", "✓", "Collapse", "Irrelevant", "Irrelevant",

  "Algebraic Connectivity (λ₂)", "Spectral connectivity (Fiedler value)", "Structural", "Largest Component", "Collapse; remove loops", "✓", "Do NOT use",

  # --------------------- INTERCONNECTEDNESS ---------------------
  "Edge Density", "Edges ÷ possible edges", "Interconnectedness", "✓", "Collapse", "Irrelevant", "Irrelevant",

  "Network Cohesion (Reachability Ratio)", "Fraction of reachable ordered pairs", "Interconnectedness", "✓", "Collapse", "Irrelevant", "Irrelevant",

  "Global Clustering Coefficient", "Triangle closure ratio", "Interconnectedness", "✓", "Collapse", "✓ (Barrat local → mean)", "Irrelevant",

  "Assortativity", "Mixing by attribute", "Interconnectedness", "✓", "Collapse", "✓ (strength assort.)", "✓ (degree assort.)",

  # --------------------- CENTRALIZATION ---------------------
  "Degree Centralization", "Inequality of degree distribution", "Centralization", "✓", "Collapse", "Consider Strength Centralization", "✓",

  "Strength Centralization", "Inequality of weighted degree", "Centralization", "✓", "Collapse", "✓", "Irrelevant",

  "Closeness Centralization", "Inequality in closeness", "Centralization", "Largest Component", "Collapse", "1/weight", "✓",

  "Betweenness Centralization", "Inequality in shortest path mediation", "Centralization", "Largest Component", "Collapse", "1/weight", "✓",

  "Eigenvector Centralization", "Inequality in spectral influence", "Centralization", "✓", "Collapse", "✓", "Do NOT use",

  # --------------------- EFFICIENCY ---------------------
  "Global Efficiency", "Global ease of communication", "Efficiency", "✓", "Collapse", "1/weight", "✓",

  "Average Local Efficiency", "Neighborhood-level efficiency", "Efficiency", "✓", "Collapse", "1/weight", "✓",

  "Average Shortest Path Length", "Mean geodesic distance", "Efficiency", "Largest Component", "Collapse", "1/weight", "✓"
)

# Color-blind-safe palette (Okabe-Ito)
category_colors <- c(
  Structural         = "#a6cee3",
  Interconnectedness = "#b2df8a",
  Centralization     = "#fdbf6f",
  Efficiency         = "#cab2d6"
)

global_measures_table |>
  gt() |>
  tab_header(
    title = "Drug Smuggling Graph - Measures",
    subtitle = "Various measures and metrics for Caviar Drug Smuggling network"
  ) |>
  data_color(
    columns = everything(),   # columns to tint
    fn = function(cols) {
      category <- global_measures_table$Category
      category_colors[category]
    }
  ) |>
  tab_options(table.font.size = 12)
```
